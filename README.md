# FALCON: Fault Localization with Contrastive Learning

Implementation of FALCON (ICSE'25) - A deep learning approach for software fault localization using Graph Neural Networks and Contrastive Learning.

## ğŸ“‹ Overview

FALCON uses a **two-phase training strategy** to localize faults in software:

1. **Phase 1: Representation Learning** - Learn semantic graph representations using contrastive learning
2. **Phase 2: Fault Localization** - Fine-tune the model to rank faulty functions

## ğŸ—ï¸ Project Structure

```
Falcon/
â”œâ”€â”€ data_preprocessing/           # ğŸ“¦ DATA PREPROCESSING MODULE (Independent)
â”‚   â”œâ”€â”€ config.py                 # Config for preprocessing
â”‚   â”œâ”€â”€ log_parser.py             # Parse execution logs
â”‚   â”œâ”€â”€ graph_builder.py          # Build PyG graphs
â”‚   â”œâ”€â”€ preprocess.py             # Main preprocessing script
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ processed_data/               # ğŸ’¾ PREPROCESSED GRAPHS (.pt files)
â”‚
â”œâ”€â”€ src/                          # ğŸ§  TRAINING MODULE
â”‚   â”œâ”€â”€ config.py                 # Config for training
â”‚   â”œâ”€â”€ models/                   # Neural network models
â”‚   â”‚   â”œâ”€â”€ encoder.py            # GGNN encoder
â”‚   â”‚   â”œâ”€â”€ heads.py              # Projection & Rank heads
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ training/                 # Training logic
â”‚   â”‚   â”œâ”€â”€ losses.py             # Loss functions
â”‚   â”‚   â”œâ”€â”€ trainer.py            # Two-phase trainer
â”‚   â”‚   â”œâ”€â”€ augmentation.py       # Graph augmentation
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â””â”€â”€ metrics.py            # Evaluation metrics
â”‚
â”œâ”€â”€ training.py                   # ğŸš€ Training script
â”œâ”€â”€ results/                      # ğŸ“Š Training results (CSV, JSON)
â””â”€â”€ README.md
```

## ğŸ”„ Workflow

FALCON cÃ³ **2 modules Ä‘á»™c láº­p**:

### 1ï¸âƒ£ Data Preprocessing Module (`data_preprocessing/`)
- **Má»¥c Ä‘Ã­ch**: Parse logs vÃ  build graphs tá»« raw data
- **Input**: `../data_tcpdump/`
- **Output**: `processed_data/*.pt`
- **Äá»™c láº­p**: CÃ³ config vÃ  dependencies riÃªng

### 2ï¸âƒ£ Training Module (`src/` + `training.py`)
- **Má»¥c Ä‘Ã­ch**: Train model vÃ  evaluate
- **Input**: `processed_data/*.pt` 
- **Output**: `results/*.csv`, `results/*.json`
- **Äá»™c láº­p**: Chá»‰ Ä‘á»c tá»« processed_data, khÃ´ng cáº§n raw data

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- PyTorch 2.0+
- PyTorch Geometric
- CUDA (optional)

### Installation

```bash
cd Falcon

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # macOS/Linux

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
```

## ğŸ“Š Usage

### Step 1: Data Preprocessing

**Option A: Python Script (Local)**

```bash
cd data_preprocessing

# Run preprocessing
python preprocess.py

# Options:
python preprocess.py --force                        # Force rebuild
python preprocess.py --versions v1-12896 v2-12893  # Specific versions
```

**Option B: Jupyter Notebook (Colab/Kaggle/Local)**

```bash
cd data_preprocessing
jupyter notebook preprocess.ipynb

# Or upload preprocess.ipynb to Google Colab / Kaggle
# See data_preprocessing/NOTEBOOK_GUIDE.md for details
```

**Output**: `../processed_data/*.pt` files

---

### Step 2: Training

```bash
cd ..  # Back to Falcon/

# Run training (80/20 split)
python training.py

# Options:
python training.py --train_ratio 0.7      # 70% train, 30% test
python training.py --epochs1 5 --epochs2 5  # Custom epochs
python training.py --seed 123             # Different seed
```

**Output**: `results/falcon_results_*.csv` and `.json`

---

### Quick Start (All Steps)

```bash
cd Falcon
source venv/bin/activate

# Step 1: Preprocess
cd data_preprocessing
python preprocess.py
cd ..

# Step 2: Train
python training.py
```

---

## â˜ï¸ Kaggle Training (Recommended for GPU)

**Cháº¡y training trÃªn Kaggle vá»›i GPU T4 (free)** - Nhanh hÆ¡n vÃ  khÃ´ng tá»‘n tÃ i nguyÃªn local!

### Quick Setup

1. **Upload code lÃªn GitHub** (xem `KAGGLE_SETUP.md`)
2. **Upload dataset lÃªn Kaggle Datasets**
3. **Táº¡o Kaggle Notebook** vá»›i GPU enabled
4. **Run `kaggle_training.ipynb`**

### Detailed Guide

ğŸ“– **Xem hÆ°á»›ng dáº«n chi tiáº¿t**: [`KAGGLE_SETUP.md`](KAGGLE_SETUP.md)

**Lá»£i Ã­ch**:
- âœ… GPU T4 free (nhanh hÆ¡n CPU 10-20x)
- âœ… KhÃ´ng tá»‘n RAM local
- âœ… Dá»… share vÃ  reproduce
- âœ… Auto-save results

**Expected Runtime**: 20-45 phÃºt (vs 2-4 giá» trÃªn CPU)

---

## ğŸ’» CPU/GPU Support

FALCON há»— trá»£ **cáº£ CPU vÃ  GPU** vá»›i kháº£ nÄƒng **cross-platform**:

### Device Detection

Training tá»± Ä‘á»™ng detect device:

```bash
# Auto-detect (recommended)
python training.py

# Force CPU
python training.py --device cpu

# Force GPU (if available)
python training.py --device cuda
```

### Cross-Platform Workflow

âœ… **Preprocessing trÃªn GPU (Kaggle) â†’ Training trÃªn CPU (Local)**
```bash
# Kaggle: Run preprocess.ipynb vá»›i T4 GPU
# Download processed_data/ vá» local
# MacBook: python training.py  # Auto-load vá»›i CPU
```

âœ… **Preprocessing trÃªn CPU â†’ Training trÃªn GPU**
```bash
# Local: cd data_preprocessing && python preprocess.py
# Upload processed_data/ lÃªn Colab/Kaggle
# GPU: python training.py --device cuda
```

**LÃ½ do hoáº¡t Ä‘á»™ng**: 
- Preprocessing táº¡o files `.pt` portable (device-independent)
- Training tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i tensors vá»›i `map_location`

ğŸ“– Xem thÃªm: `CPU_GPU_SUPPORT.md`

---

## âš™ï¸ Configuration

### Preprocessing Config

Edit `data_preprocessing/config.py`:

```python
RAW_DATA_PATH = "../../data_tcpdump"
OUTPUT_PATH = "../processed_data"
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
```

### Training Config

Edit `src/config.py`:

```python
# Model
EMBEDDING_DIM = 64
HIDDEN_DIM = 128
NUM_GNN_LAYERS = 3

# Training
PHASE1_EPOCHS = 10
PHASE2_EPOCHS = 10
LEARNING_RATE_PHASE1 = 1e-3
LEARNING_RATE_PHASE2 = 1e-4

# Device
DEVICE = "cuda"  # or "cpu"
```

## ğŸ“ˆ Evaluation Metrics

- **Top-K Accuracy**: % of test cases where faulty function is in top-K
- **MFR (Mean First Rank)**: Average rank (lower is better)
- **MRR (Mean Reciprocal Rank)**: Average of 1/rank (higher is better)

### Example Results

```
======================================================================
                         FALCON Results
======================================================================

Top-K Accuracy (%):
  Top-1       65.00%
  Top-3       82.50%
  Top-5       91.25%
  Top-10      97.50%

Ranking Metrics:
  MFR          2.30
  MRR        0.7300
======================================================================
```

## ğŸ”¬ Architecture

### Graph Structure
- **Nodes**: Log, Package, File, Method
- **Edges**: Hierarchical + Sequential
- **Features**: SentenceBERT (384-dim)

### Model
- **Encoder**: GGNN (Gated Graph Neural Network)
- **Phase 1**: Contrastive Learning (Node + Graph)
- **Phase 2**: Listwise Ranking

## ğŸ“ Command Options

### data_preprocessing/preprocess.py

| Option | Description |
|--------|-------------|
| `--data_path` | Path to raw data |
| `--output_path` | Path to save .pt files |
| `--force` | Force rebuild (ignore cache) |
| `--versions` | Specific versions to process |

### training.py

| Option | Default | Description |
|--------|---------|-------------|
| `--data_path` | `./processed_data` | Path to .pt files |
| `--train_ratio` | 0.8 | Train/test split ratio |
| `--seed` | 42 | Random seed |
| `--epochs1` | 10 | Phase 1 epochs |
| `--epochs2` | 10 | Phase 2 epochs |
| `--device` | auto | cuda or cpu |

## ğŸ“ Output Files

### Preprocessing
```
processed_data/
â”œâ”€â”€ v1-12896.pt
â”œâ”€â”€ v2-12893.pt
â”œâ”€â”€ ...
â”œâ”€â”€ embedding_cache.pkl
â””â”€â”€ preprocessing_summary.json
```

### Training
```
results/
â”œâ”€â”€ falcon_results_20260113_120000.csv
â””â”€â”€ falcon_results_20260113_120000.json
```

## ğŸ¯ Key Features

âœ… **Modular Design**: Preprocessing vÃ  Training hoÃ n toÃ n Ä‘á»™c láº­p

âœ… **Caching**: Preprocessed graphs Ä‘Æ°á»£c cache Ä‘á»ƒ tÄƒng tá»‘c

âœ… **Flexible**: Dá»… dÃ ng thay Ä‘á»•i config vÃ  parameters

âœ… **Reproducible**: Random seed cho káº¿t quáº£ nháº¥t quÃ¡n

## ğŸ“š Data Format

### Input: Raw Logs
```
../data_tcpdump/
â”œâ”€â”€ v1-12896/fail/*.log
â”œâ”€â”€ v2-12893/fail/*.log
â””â”€â”€ ground_truth.json
```

### Intermediate: Processed Graphs
```
processed_data/
â””â”€â”€ v*.pt  # PyTorch Geometric Data objects
```

### Output: Results
```
results/
â”œâ”€â”€ *.csv  # Detailed rankings
â””â”€â”€ *.json # Full results with metadata
```
